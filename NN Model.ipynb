{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, LSTM\n",
    "from keras.layers import Dropout, Dense, TimeDistributed\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import compute_class_weight\n",
    "from tqdm import tqdm\n",
    "from python_speech_features import mfcc\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import pickle\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from cfg import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Audio_Filenames</th>\n",
       "      <th>track_genre_1</th>\n",
       "      <th>track_genre_2</th>\n",
       "      <th>length</th>\n",
       "      <th>multi_genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4em001_01_Mideast-Darkness_703611.wav</td>\n",
       "      <td>Atmosphere</td>\n",
       "      <td>World Music</td>\n",
       "      <td>4.631.510.204.081.630</td>\n",
       "      <td>Atmosphere World Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4em001_02_Desert-Search_703612.wav</td>\n",
       "      <td>Atmosphere</td>\n",
       "      <td>World Music</td>\n",
       "      <td>96.6</td>\n",
       "      <td>Atmosphere World Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4em001_03_Qasidah_703613.wav</td>\n",
       "      <td>Atmosphere</td>\n",
       "      <td>World Music</td>\n",
       "      <td>8.347.827.664.399.090</td>\n",
       "      <td>Atmosphere World Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4em001_04_Desert-War_703614.wav</td>\n",
       "      <td>Atmosphere</td>\n",
       "      <td>World Music</td>\n",
       "      <td>10.132.979.591.836.700</td>\n",
       "      <td>Atmosphere World Music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4em001_05_Desert-War---Lite_703615.wav</td>\n",
       "      <td>Atmosphere</td>\n",
       "      <td>World Music</td>\n",
       "      <td>9.382.977.324.263.030</td>\n",
       "      <td>Atmosphere World Music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                         Audio_Filenames track_genre_1  \\\n",
       "0           0   4em001_01_Mideast-Darkness_703611.wav    Atmosphere   \n",
       "1           1      4em001_02_Desert-Search_703612.wav    Atmosphere   \n",
       "2           2            4em001_03_Qasidah_703613.wav    Atmosphere   \n",
       "3           3         4em001_04_Desert-War_703614.wav    Atmosphere   \n",
       "4           4  4em001_05_Desert-War---Lite_703615.wav    Atmosphere   \n",
       "\n",
       "  track_genre_2                  length            multi_genres  \n",
       "0   World Music   4.631.510.204.081.630  Atmosphere World Music  \n",
       "1   World Music                    96.6  Atmosphere World Music  \n",
       "2   World Music   8.347.827.664.399.090  Atmosphere World Music  \n",
       "3   World Music  10.132.979.591.836.700  Atmosphere World Music  \n",
       "4   World Music   9.382.977.324.263.030  Atmosphere World Music  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_genres = pd.read_csv(\"clean_audio_genres.csv\", sep=\";\")\n",
    "audio_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_genres.set_index('Audio_Filenames', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in audio_genres.index:\n",
    "    audio_genres.at[f, 'clean_length'] = 40.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Atmosphere            3899\n",
       "Filmscore             3214\n",
       "Rock                  3172\n",
       "Electronica           2023\n",
       "Country, Folk         1920\n",
       "Hip Hop, Rap          1875\n",
       "Others                1661\n",
       "Classical Music       1442\n",
       "Easy Listening        1369\n",
       "Dance                 1286\n",
       "Ambient, Chill        1144\n",
       "Indie, Alternative    1141\n",
       "Pop                   1088\n",
       "Funk, Soul             941\n",
       "World Music            927\n",
       "Jazz                   863\n",
       "House                  739\n",
       "Latin                  446\n",
       "Blues                  309\n",
       "60ies                  303\n",
       "RnB                    162\n",
       "Swing                  124\n",
       "Acoustic                99\n",
       "Orchestral              95\n",
       "Kids                    77\n",
       "Christmas               72\n",
       "Hard, Heavy             70\n",
       "Drone                   43\n",
       "Trailer                 29\n",
       "Sound Design            10\n",
       "Name: track_genre_1, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newoccur_col1 = audio_genres[\"track_genre_1\"].value_counts()\n",
    "newoccur_col1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pop                   3472\n",
       "Electronica           2674\n",
       "Others                2481\n",
       "Ambient, Chill        2365\n",
       "Filmscore             1657\n",
       "Classical Music       1263\n",
       "World Music           1263\n",
       "Indie, Alternative     613\n",
       "Orchestral             593\n",
       "Acoustic               558\n",
       "Kids                   531\n",
       "Sound Design           520\n",
       "Trailer                484\n",
       "Hard, Heavy            471\n",
       "Jazz                   461\n",
       "Drone                  369\n",
       "Christmas              360\n",
       "Blues                  332\n",
       "Swing                  322\n",
       "Dance                  313\n",
       "RnB                    266\n",
       "Easy Listening         243\n",
       "Atmosphere             220\n",
       "Funk, Soul             217\n",
       "60ies                  141\n",
       "House                  127\n",
       "Country, Folk           95\n",
       "Hip Hop, Rap            66\n",
       "Rock                    57\n",
       "Latin                   36\n",
       "Name: track_genre_2, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newoccur_col2 = audio_genres[\"track_genre_2\"].value_counts()\n",
    "newoccur_col2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Filmscore             4871\n",
       "Electronica           4697\n",
       "Pop                   4560\n",
       "Others                4142\n",
       "Atmosphere            4119\n",
       "Ambient, Chill        3509\n",
       "Rock                  3229\n",
       "Classical Music       2705\n",
       "World Music           2190\n",
       "Country, Folk         2015\n",
       "Hip Hop, Rap          1941\n",
       "Indie, Alternative    1754\n",
       "Easy Listening        1612\n",
       "Dance                 1599\n",
       "Jazz                  1324\n",
       "Funk, Soul            1158\n",
       "House                  866\n",
       "Orchestral             688\n",
       "Acoustic               657\n",
       "Blues                  641\n",
       "Kids                   608\n",
       "Hard, Heavy            541\n",
       "Sound Design           530\n",
       "Trailer                513\n",
       "Latin                  482\n",
       "Swing                  446\n",
       "60ies                  444\n",
       "Christmas              432\n",
       "RnB                    428\n",
       "Drone                  412\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dist = newoccur_col1 + newoccur_col2\n",
    "class_dist.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = ['Drone', 'RnB', 'Christmas', '60ies', 'Swing', 'Latin', 'Trailer', 'Sound Design', 'Hard, Heavy', 'Kids', 'Blues', 'Acoustic', 'Orchestral', 'House', 'Funk, Soul', 'Jazz', 'Dance', 'Easy Listening', 'Indie, Alternative', 'Country, Folk', 'Hip Hop, Rap', 'World Music', 'Classical Music', 'Rock', 'Ambient, Chill', 'Others', 'Pop', 'Atmosphere', 'Electronica', 'Filmscore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(np.unique(genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = int(audio_genres['clean_length'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dist = class_dist/class_dist.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Filmscore             0.091710\n",
       "Electronica           0.088434\n",
       "Pop                   0.085855\n",
       "Others                0.077985\n",
       "Atmosphere            0.077552\n",
       "Ambient, Chill        0.066067\n",
       "Rock                  0.060795\n",
       "Classical Music       0.050929\n",
       "World Music           0.041233\n",
       "Country, Folk         0.037938\n",
       "Hip Hop, Rap          0.036545\n",
       "Indie, Alternative    0.033024\n",
       "Easy Listening        0.030350\n",
       "Dance                 0.030106\n",
       "Jazz                  0.024928\n",
       "Funk, Soul            0.021803\n",
       "House                 0.016305\n",
       "Orchestral            0.012954\n",
       "Acoustic              0.012370\n",
       "Blues                 0.012069\n",
       "Kids                  0.011447\n",
       "Hard, Heavy           0.010186\n",
       "Sound Design          0.009979\n",
       "Trailer               0.009659\n",
       "Latin                 0.009075\n",
       "Swing                 0.008397\n",
       "60ies                 0.008360\n",
       "Christmas             0.008134\n",
       "RnB                   0.008058\n",
       "Drone                 0.007757\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_dist.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = np.random.choice(class_dist.index, p=prob_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_data():\n",
    "    if os.path.isfile(config.p_path):\n",
    "        print('Loading existing data for {} model'.format(config.mode))\n",
    "        with open(config.p_path, 'rb') as handle:\n",
    "            tmp = pickle.load(handle)\n",
    "            return tmp\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rand_feat():\n",
    "    tmp = check_data()\n",
    "    if tmp:\n",
    "        return tmp.data[0], tmp.data[1]\n",
    "    X = []\n",
    "    y = []\n",
    "    _min, _max = float('inf'), -float('inf')\n",
    "    for _ in tqdm(range(n_samples)):\n",
    "        rand_class = np.random.choice(class_dist.index, p=prob_dist)\n",
    "        f = np.random.choice(audio_genres[audio_genres.multi_genres.str.contains(rand_class)].index)\n",
    "        rate, wav = wavfile.read('40secwav/'+f)\n",
    "        rand_index = np.random.randint(0, wav.shape[0]-config.step)\n",
    "        sample = wav[rand_index:rand_index+config.step]\n",
    "        X_sample = mfcc(sample, rate, \n",
    "                       numcep=config.nfeat, nfilt=config.nfilt, nfft=config.nfft)\n",
    "        if X_sample.shape != (19,13): #avoid faulty file\n",
    "            print(f)\n",
    "            continue\n",
    "        _min = min(np.amin(X_sample), _min)\n",
    "        _max = max(np.amax(X_sample), _max)\n",
    "        X.append(X_sample)\n",
    "        y.append(\n",
    "                (audio_genres.at[f, 'track_genre_1'], audio_genres.at[f, 'track_genre_2'])\n",
    "        )\n",
    "    config.min = _min\n",
    "    config.max = _max\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X = (X - _min) / (_max - _min)\n",
    "    if config.mode == 'conv':\n",
    "        X = X.reshape(X.shape[0], X.shape[1], X.shape[2], 1)\n",
    "    elif config.mode == 'time':\n",
    "        X = X.reshape(X.shape[0], X.shape[1], X.shape[2])\n",
    "    y = one_hot_encode(y, classes)\n",
    "    config.data = (X, y)\n",
    "    \n",
    "    with open(config.p_path, 'wb') as handle:\n",
    "        pickle.dump(config, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return X, y\n",
    "\n",
    "def one_hot_encode(y, genres):\n",
    "    surrogate = genres + ['nan']\n",
    "    y_vectorized = np.zeros((len(y), len(surrogate)))\n",
    "\n",
    "    for i, (l1, l2) in enumerate(y):\n",
    "        index = (surrogate.index(l1), surrogate.index(l2))\n",
    "        y_vectorized[i, index] = 1\n",
    "\n",
    "    y_vectorized = y_vectorized[:, :-1]\n",
    "    return tf.convert_to_tensor(y_vectorized, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(8, (7,7), activation='tanh', strides=(1,1),\n",
    "                    padding='same', input_shape=input_shape))\n",
    "    model.add(MaxPool2D((2,2), padding='same'))\n",
    "    model.add(Conv2D(16, (5,5), activation='relu', strides=(1,1),\n",
    "                    padding='same'))\n",
    "    model.add(MaxPool2D((2,2), padding='same'))\n",
    "    model.add(Conv2D(16, (3,3), activation='relu', strides=(1,1),\n",
    "                    padding='same'))\n",
    "    model.add(MaxPool2D((2,2), padding='same'))\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', strides=(1,1),\n",
    "                    padding='same'))\n",
    "    model.add(MaxPool2D((2,2), padding='same'))\n",
    "    model.add(Conv2D(32, (3,3), activation='relu', strides=(1,1),\n",
    "                    padding='same'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu', activity_regularizer=l2(0.001)))\n",
    "    model.add(Dense(30, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(mode='conv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing data for conv model\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 19, 13, 8)         400       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 10, 7, 8)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 10, 7, 16)         3216      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 5, 4, 16)          2320      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 2, 32)          4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 2, 1, 32)          9248      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                1950      \n",
      "=================================================================\n",
      "Total params: 25,934\n",
      "Trainable params: 25,934\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "    2/10817 [..............................] - ETA: 57:05 - loss: 0.6865 - binary_accuracy: 0.5979WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.310480). Check your callbacks.\n",
      "10817/10817 [==============================] - 247s 23ms/step - loss: 0.2143 - binary_accuracy: 0.9382 - val_loss: 0.2077 - val_binary_accuracy: 0.9386\n",
      "Epoch 2/50\n",
      "10817/10817 [==============================] - 236s 22ms/step - loss: 0.2077 - binary_accuracy: 0.9386 - val_loss: 0.2068 - val_binary_accuracy: 0.9386\n",
      "Epoch 3/50\n",
      "10817/10817 [==============================] - 225s 21ms/step - loss: 0.2066 - binary_accuracy: 0.9386 - val_loss: 0.2066 - val_binary_accuracy: 0.9386\n",
      "Epoch 4/50\n",
      "10817/10817 [==============================] - 226s 21ms/step - loss: 0.2061 - binary_accuracy: 0.9386 - val_loss: 0.2069 - val_binary_accuracy: 0.9386\n",
      "Epoch 5/50\n",
      "10817/10817 [==============================] - 223s 21ms/step - loss: 0.2056 - binary_accuracy: 0.9386 - val_loss: 0.2060 - val_binary_accuracy: 0.9386\n",
      "Epoch 6/50\n",
      "10817/10817 [==============================] - 222s 21ms/step - loss: 0.2053 - binary_accuracy: 0.9386 - val_loss: 0.2060 - val_binary_accuracy: 0.9387\n",
      "Epoch 7/50\n",
      "10817/10817 [==============================] - 228s 21ms/step - loss: 0.2050 - binary_accuracy: 0.9386 - val_loss: 0.2058 - val_binary_accuracy: 0.9386\n",
      "Epoch 8/50\n",
      "10817/10817 [==============================] - 226s 21ms/step - loss: 0.2048 - binary_accuracy: 0.9386 - val_loss: 0.2060 - val_binary_accuracy: 0.9387\n",
      "Epoch 9/50\n",
      "10817/10817 [==============================] - 228s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9386 - val_loss: 0.2053 - val_binary_accuracy: 0.9387\n",
      "Epoch 10/50\n",
      "10817/10817 [==============================] - 227s 21ms/step - loss: 0.2045 - binary_accuracy: 0.9386 - val_loss: 0.2054 - val_binary_accuracy: 0.9386\n",
      "Epoch 11/50\n",
      "10817/10817 [==============================] - 227s 21ms/step - loss: 0.2043 - binary_accuracy: 0.9386 - val_loss: 0.2059 - val_binary_accuracy: 0.9387\n",
      "Epoch 12/50\n",
      "10817/10817 [==============================] - 229s 21ms/step - loss: 0.2042 - binary_accuracy: 0.9386 - val_loss: 0.2051 - val_binary_accuracy: 0.9386\n",
      "Epoch 13/50\n",
      "10817/10817 [==============================] - 229s 21ms/step - loss: 0.2041 - binary_accuracy: 0.9386 - val_loss: 0.2050 - val_binary_accuracy: 0.9386\n",
      "Epoch 14/50\n",
      "10817/10817 [==============================] - 224s 21ms/step - loss: 0.2040 - binary_accuracy: 0.9386 - val_loss: 0.2063 - val_binary_accuracy: 0.9386\n",
      "Epoch 15/50\n",
      "10817/10817 [==============================] - 223s 21ms/step - loss: 0.2039 - binary_accuracy: 0.9386 - val_loss: 0.2054 - val_binary_accuracy: 0.9386\n",
      "Epoch 16/50\n",
      "10817/10817 [==============================] - 226s 21ms/step - loss: 0.2038 - binary_accuracy: 0.9386 - val_loss: 0.2053 - val_binary_accuracy: 0.9387\n",
      "Epoch 17/50\n",
      "10817/10817 [==============================] - 236s 22ms/step - loss: 0.2037 - binary_accuracy: 0.9386 - val_loss: 0.2044 - val_binary_accuracy: 0.9386\n",
      "Epoch 18/50\n",
      "10817/10817 [==============================] - 226s 21ms/step - loss: 0.2037 - binary_accuracy: 0.9386 - val_loss: 0.2055 - val_binary_accuracy: 0.9386\n",
      "Epoch 19/50\n",
      "10817/10817 [==============================] - 225s 21ms/step - loss: 0.2037 - binary_accuracy: 0.9386 - val_loss: 0.2045 - val_binary_accuracy: 0.9387\n",
      "Epoch 20/50\n",
      "10817/10817 [==============================] - 223s 21ms/step - loss: 0.2036 - binary_accuracy: 0.9386 - val_loss: 0.2057 - val_binary_accuracy: 0.9386\n",
      "Epoch 21/50\n",
      "10817/10817 [==============================] - 223s 21ms/step - loss: 0.2036 - binary_accuracy: 0.9386 - val_loss: 0.2062 - val_binary_accuracy: 0.9386\n",
      "Epoch 22/50\n",
      "10817/10817 [==============================] - 223s 21ms/step - loss: 0.2036 - binary_accuracy: 0.9386 - val_loss: 0.2047 - val_binary_accuracy: 0.9387\n",
      "Epoch 23/50\n",
      "10817/10817 [==============================] - 230s 21ms/step - loss: 0.2035 - binary_accuracy: 0.9386 - val_loss: 0.2041 - val_binary_accuracy: 0.9386\n",
      "Epoch 24/50\n",
      "10817/10817 [==============================] - 244s 23ms/step - loss: 0.2034 - binary_accuracy: 0.9386 - val_loss: 0.2044 - val_binary_accuracy: 0.9386\n",
      "Epoch 25/50\n",
      "10817/10817 [==============================] - 242s 22ms/step - loss: 0.2034 - binary_accuracy: 0.9386 - val_loss: 0.2050 - val_binary_accuracy: 0.9386\n",
      "Epoch 26/50\n",
      "10817/10817 [==============================] - 241s 22ms/step - loss: 0.2034 - binary_accuracy: 0.9386 - val_loss: 0.2047 - val_binary_accuracy: 0.9386\n",
      "Epoch 27/50\n",
      "10817/10817 [==============================] - 241s 22ms/step - loss: 0.2033 - binary_accuracy: 0.9386 - val_loss: 0.2052 - val_binary_accuracy: 0.9387\n",
      "Epoch 28/50\n",
      "10817/10817 [==============================] - 241s 22ms/step - loss: 0.2033 - binary_accuracy: 0.9386 - val_loss: 0.2042 - val_binary_accuracy: 0.9386\n",
      "Epoch 29/50\n",
      "10817/10817 [==============================] - 239s 22ms/step - loss: 0.2032 - binary_accuracy: 0.9386 - val_loss: 0.2062 - val_binary_accuracy: 0.9386\n",
      "Epoch 30/50\n",
      "10817/10817 [==============================] - 238s 22ms/step - loss: 0.2033 - binary_accuracy: 0.9386 - val_loss: 0.2051 - val_binary_accuracy: 0.9387\n",
      "Epoch 31/50\n",
      "10817/10817 [==============================] - 240s 22ms/step - loss: 0.2032 - binary_accuracy: 0.9386 - val_loss: 0.2055 - val_binary_accuracy: 0.9385\n",
      "Epoch 32/50\n",
      "10817/10817 [==============================] - 240s 22ms/step - loss: 0.2032 - binary_accuracy: 0.9386 - val_loss: 0.2049 - val_binary_accuracy: 0.9387\n",
      "Epoch 33/50\n",
      "10817/10817 [==============================] - 241s 22ms/step - loss: 0.2032 - binary_accuracy: 0.9386 - val_loss: 0.2048 - val_binary_accuracy: 0.9387\n",
      "Epoch 34/50\n",
      "10817/10817 [==============================] - 241s 22ms/step - loss: 0.2031 - binary_accuracy: 0.9386 - val_loss: 0.2049 - val_binary_accuracy: 0.9386\n",
      "Epoch 35/50\n",
      "10817/10817 [==============================] - 240s 22ms/step - loss: 0.2032 - binary_accuracy: 0.9386 - val_loss: 0.2043 - val_binary_accuracy: 0.9386\n",
      "Epoch 36/50\n",
      "10817/10817 [==============================] - 236s 22ms/step - loss: 0.2031 - binary_accuracy: 0.9386 - val_loss: 0.2043 - val_binary_accuracy: 0.9387\n",
      "Epoch 37/50\n",
      "10817/10817 [==============================] - 232s 21ms/step - loss: 0.2031 - binary_accuracy: 0.9386 - val_loss: 0.2044 - val_binary_accuracy: 0.9387\n",
      "Epoch 38/50\n",
      "10817/10817 [==============================] - 230s 21ms/step - loss: 0.2031 - binary_accuracy: 0.9386 - val_loss: 0.2044 - val_binary_accuracy: 0.9386\n",
      "Epoch 39/50\n",
      "10817/10817 [==============================] - 236s 22ms/step - loss: 0.2030 - binary_accuracy: 0.9386 - val_loss: 0.2047 - val_binary_accuracy: 0.9386\n",
      "Epoch 40/50\n",
      "10817/10817 [==============================] - 239s 22ms/step - loss: 0.2031 - binary_accuracy: 0.9386 - val_loss: 0.2041 - val_binary_accuracy: 0.9385\n",
      "Epoch 41/50\n",
      "10817/10817 [==============================] - 239s 22ms/step - loss: 0.2030 - binary_accuracy: 0.9386 - val_loss: 0.2047 - val_binary_accuracy: 0.9386\n",
      "Epoch 42/50\n",
      "10817/10817 [==============================] - 237s 22ms/step - loss: 0.2030 - binary_accuracy: 0.9386 - val_loss: 0.2046 - val_binary_accuracy: 0.9386\n",
      "Epoch 43/50\n",
      "10817/10817 [==============================] - 240s 22ms/step - loss: 0.2030 - binary_accuracy: 0.9386 - val_loss: 0.2040 - val_binary_accuracy: 0.9385\n",
      "Epoch 44/50\n",
      "10817/10817 [==============================] - 241s 22ms/step - loss: 0.2030 - binary_accuracy: 0.9386 - val_loss: 0.2041 - val_binary_accuracy: 0.9386\n",
      "Epoch 45/50\n",
      "10817/10817 [==============================] - 228s 21ms/step - loss: 0.2030 - binary_accuracy: 0.9386 - val_loss: 0.2049 - val_binary_accuracy: 0.9387\n",
      "Epoch 46/50\n",
      "10817/10817 [==============================] - 237s 22ms/step - loss: 0.2030 - binary_accuracy: 0.9386 - val_loss: 0.2048 - val_binary_accuracy: 0.9387\n",
      "Epoch 47/50\n",
      "10817/10817 [==============================] - 242s 22ms/step - loss: 0.2030 - binary_accuracy: 0.9386 - val_loss: 0.2045 - val_binary_accuracy: 0.9385\n",
      "Epoch 48/50\n",
      "10817/10817 [==============================] - 240s 22ms/step - loss: 0.2030 - binary_accuracy: 0.9386 - val_loss: 0.2048 - val_binary_accuracy: 0.9386\n",
      "Epoch 49/50\n",
      "10817/10817 [==============================] - 241s 22ms/step - loss: 0.2030 - binary_accuracy: 0.9386 - val_loss: 0.2042 - val_binary_accuracy: 0.9386\n",
      "Epoch 50/50\n",
      "10817/10817 [==============================] - 246s 23ms/step - loss: 0.2030 - binary_accuracy: 0.9386 - val_loss: 0.2053 - val_binary_accuracy: 0.9387\n",
      "WARNING:tensorflow:From C:\\Users\\victo\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: models\\conv.model\\assets\n"
     ]
    }
   ],
   "source": [
    "if config.mode == 'conv':\n",
    "    X, y = build_rand_feat()\n",
    "    def y_flat(y,thresh=0.):\n",
    "        mask= y>thresh\n",
    "        r,c = np.where(mask)\n",
    "        out = np.empty(len(y), dtype=object)\n",
    "        grp_idx = np.r_[0, np.flatnonzero(r[:-1] != r[1:])+1,len(r)]\n",
    "        valid_rows = r[np.r_[True,r[:-1] != r[1:]]]\n",
    "        for (row,i,j) in zip(valid_rows,grp_idx[:-1],grp_idx[1:]):\n",
    "            out[row] = c[i:j]\n",
    "        return out\n",
    "    y_flat2 = np.concatenate(y_flat(y,thresh=0.))\n",
    "    unique, counts = np.unique(y_flat2, return_counts=True)\n",
    "    total_samples = np.sum(counts)\n",
    "    dist_labels = counts/total_samples\n",
    "    average_weights = 1/30\n",
    "    label_weights = average_weights/dist_labels\n",
    "    dict_weights = dict(zip(unique, label_weights))\n",
    "    \n",
    "    input_shape = (X.shape[1], X.shape[2], 1)\n",
    "    model = get_conv_model()\n",
    "    \n",
    "    \n",
    "elif config.mode == 'time':\n",
    "    X, y = build_rand_feat()\n",
    "    def y_flat(y,thresh=0.):\n",
    "        mask= y>thresh\n",
    "        r,c = np.where(mask)\n",
    "        out = np.empty(len(y), dtype=object)\n",
    "        grp_idx = np.r_[0, np.flatnonzero(r[:-1] != r[1:])+1,len(r)]\n",
    "        valid_rows = r[np.r_[True,r[:-1] != r[1:]]]\n",
    "        for (row,i,j) in zip(valid_rows,grp_idx[:-1],grp_idx[1:]):\n",
    "            out[row] = c[i:j]\n",
    "        return out\n",
    "    y_flat2 = np.concatenate(y_flat(y,thresh=0.))\n",
    "    unique, counts = np.unique(y_flat2, return_counts=True)\n",
    "    total_samples = np.sum(counts)\n",
    "    dist_labels = counts/total_samples\n",
    "    average_weights = 1/30\n",
    "    label_weights = average_weights/dist_labels\n",
    "    dict_weights = dict(zip(unique, label_weights))\n",
    "\n",
    "    input_shape = (X.shape[1], X.shape[2])\n",
    "    model = get_recurrent_model()\n",
    "    \n",
    "weights = dict_weights\n",
    "\n",
    "#checkpoint = ModelCheckpoint(config.model_path, monitor='val_loss', verbose=1, mode='max',\n",
    "                            #save_best_only=True, save_weights_only=False, save_freq='epoch')\n",
    "\n",
    "model.fit(X, y, epochs=50, validation_split=0.15, batch_size=96,\n",
    "         shuffle=True,\n",
    "         class_weight=weights,\n",
    "         callbacks=[tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='./logs', histogram_freq=0, write_graph=True, write_images=False,\n",
    "    update_freq='epoch', profile_batch=2, embeddings_freq=0,\n",
    "    embeddings_metadata=None\n",
    ")])\n",
    "\n",
    "model.save(config.model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
